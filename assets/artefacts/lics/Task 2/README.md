# Readme

Task 2 was to make the planned application from Task 1, using Python, with an accompanying readme file, that was upto 800 words long.

## <ins>Feedback</ins>

The rubrik was presented as follows:

| Component | Contribution (%) | My Score | Feedback (+/-) |
| --------- | ---------------- | -------- | ------- |
| Knowledge and Understanding | 30% | No score | + "An excellenet demonstration of knowledge and understanding, displaying some originality and in-depth understanding in all key areas of knowledge relevant to work" <br> - "You have used too many options for the users, which could have been avoided to make the application short and simple." |
| Application of Knowledge and Understanding | 30% | No score | + "An excellent demonstration of the application of knowledge and understanding to address the learning outcomes assessed by the assignment and/or application to professional practise or real-world applicability." <br> + "The GUI has been produced exceptionally well with full functionalities." <br> - "There are too many options evident on the terminal, which is a negative aspect." |  
| Structure and Presentation | 30% | No score | + "Good structure and presentation, which shows elements of presentation and structure at a professional standard." <br> + "The presentation of testing and validation look amazing with required evidences and information." <br> - "You could have paid more focus on placing all figures in the centre of the page with more information." <br> - "The presentation of the main algorithm and Python script part could have been better."|
| Academic Intregrity | 10% | No score | + "A very good demonstration of academic writing, including use of academic conventions, citations and/or referencing with no errors." <br> + "Work shows broadly accurate attempts" <br> + "You have used few sources with accuracy."|

In total, my score was 77%. I was never given a percentage breakdown of my score. However, I was given additional comments:

| Component | Feedback (+/-) |
| --------- | -------------- |
| Overall Comments | + "Overall an excellent effort" <br> + "Well-documented assigment with examples and test cases" <br> + "Good logic using for and if loop" <br> + "comments are used to explain and outputs are shown" <br> + "Brilliant use of screenshots to demonstrate the functionality" <br> + "Your implementation and discussions are excellent" <br> + "The report is organised in a brilliant way with detailed explanations" <br> + "Appropiate code has been used in terms of implmentation and use of functionalities, e.g use of object-oriented programming concepts, or functional aspects, but in general you did a brilliant work." <br> + "List positioning using list indexing has been used correctly" <br> + "The test results are correct" <br> + "Overall the coding is very good in terms of libraries and Python data structures" <br> + "Code implments the correct logic and good use of for and if" <br> + "Variables are defined correctly" <br> + "Very good use of visualisations in the report" <br> - "The report could be further extended to include more discussion and analysis." <br> - "could have discussed for implementation and instruction of how to use" <br> - "Test strategy could be described in detail"|

## <ins>Reflection</ins>

Overall, I'm happy with the score, I really enjoyed the assignment, having a chance to show off some proficiency with Python and software development but again, I found alot of the feedback more confusing than explicitly helpful.

The assignment feedback we recieve is the only way we can learn about how to do better next time. So it's suprising to only receive a few comments that provided an oppurtunity for me to improve, when my score was only 77%. I think I expected a higher score. I would be contempt with a lower score if I was given something to learn. I've used Python for many years, and I've had plenty of practise with it making applications, and solving interview style challenges based around data structures and algorithms. I currently work as a software developer too. So I'm genuinely curious on how I can improve in this field. Without a high mark, I 100% expect constructive feedback, and I don't think constructive feedback is too much to expect from an educational establishment.

Below is a list of areas of improvement I was given from the Task 2 feedback, along with my reflections. I have been critical as is expected by students a Master's course.

* I was told that I gave the user too many options. To put this in persepctive, I gave the user around 10 options in order to demonstrate all of the functionality that I was instructed to do so. I agree that a CLI application which has many options is not ideal when using a small terminal, but I feel like I was forced to do it in this case to meet the assignment expectations. I would have nested some options if I had any reason to believe 10 options is too many at a time, so I think a model answer would prevent this mistake being made. I also stated in my readme file that the final version of the application would use a VUI not CLI, so there wouldn't be a list in that case. It was specified that this was a prototype, and it's typical of demos to include longer lists than retail versions.
* I was told that I could have placed the figures in the centre of the page with more information. I have no idea what this is talking about, as no figures were used in this Task. I suspect this is a criticism of my submission for Task 1, which did include embedded figures within the application plan. Feedback like this one is frustrating to me because it displays assessment incompetency. Why didn't I receive that feedback in the Task 1 feedback? Did that affect my score for Task 2?
* I was told that the presentation of my main algorithm could have been improved. Essentially, the main algorithm was a loop that got user input, cleaned it and intepreted it, interacted with the database and then printed out text. I relied upon alot of if statements because I was instructed to use python 3.4 which doesn't support switch/case statements or the walrus operator. I created many low level functions and integrated those into the main algorithm. I agree that I could have made higher level functions too; specifically, one for for each user option, to help the main algorithm appear simpler.
* I was told my report could have been extended with more discussion and analysis. I think this is too generic and unclear to be useful. Does a readme file count as a report, or is this referring to my plan from Task 1? What needed to be analysed? There was no required analysis mentioned in the instructions of Task 2, thus I suspect this comment is another piece of feedback irrelevant to Task 2.
* I was told that I could have discussed instructions and implementations. The first paragraph of my readme contains instructions for the application, and the rest of the readme is related to implementations. That makes this confusing. A model answer might have been helpful here, if there was some presentation issue in Task 2. This comment of the feedback is unnecessarily dismissive, and appears more of a filler than anything else.
* I was told my test strategy could be described in detail. This is referring to Task 1 again I presume, where I was instructed to plan a test strategy. In my Task 2 readme, I didn't provide instructions specifically on how to enter debug mode, because I provided instructions on how to use the application as a whole, and debug mode was simply an option amongst the others. The readme file explained what debug mode does, so I don't think that was the problem either. The use of guardians to control input and output states was explained too, in the readme and in the code itself. I'm unsure how else this could be relevant to Task 2.

Beyond some minor changes, namely: function nesting and option nesting; I don't really know how to improve within this task. I don't believe the feedback alone justifies the 23% marks I lost for the assignment, given the rubrik. I would love more constructive feedback. At the moment, I find the feedback policy unethical for allowing what appears to be an ignorance of teaching-responsibility, beyond the role of qualification gatekeeping. We pay for an education, as well as the chance for obtaining a qualification, so I definately expect guidance.
